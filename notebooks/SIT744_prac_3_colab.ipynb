{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeHe2I9Ix2iM"
      },
      "source": [
        "# SIT744 Practical 3: Introduction to Keras\n",
        "\n",
        "\n",
        "*Prof. Antonio Robles-Kelly*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l--dd-g0DOiD"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "We suggest that you run this notebook using Google Colab.\n",
        "</div>\n",
        "\n",
        "## Pre-practical readings\n",
        "\n",
        "- Explore the [TensorFlow Neural Network Playground](https://playground.tensorflow.org/) to understand intuitively how a neural network works\n",
        "- Go through this [notebook](https://github.com/alzayats/Google_Colab/blob/master/2_1_a_first_look_at_a_neural_network.ipynb) for an overview of building neural-network models in Keras.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFIXRAjmedgo"
      },
      "source": [
        "## Task 1. Use Google Drive with Google Colab\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFlvka1lmAxe"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlXzf__wEj5Z"
      },
      "source": [
        "When you use Google Colab, you are allocated a virtual machine and your data on the machine will be lost once you disconnect. Therefore you should **keep your notebook, data, and program outputs in Google Drive**.\n",
        "\n",
        "To mount your Google Drive, you can use the \"Mount/Unmount Drive\" button in the `Files` tab.\n",
        "\n",
        "\n",
        "<img src=\"https://i.stack.imgur.com/Rj69d.png\" alt=\"Mount/Unmount Drive\"  width=\"400\"/>\n",
        "\n",
        "Alternatively, you can run the following code segment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3jgbIiPCCap"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytkj5X39FlvP"
      },
      "source": [
        "Then\n",
        "\n",
        "- click the URL to log into your Google account\n",
        "- copy the authorization code\n",
        "- enter the code in the input box above.\n",
        "\n",
        "(See more information [here](https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/).)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr5sJ6U7HxIr"
      },
      "source": [
        "**exercise**: Mount your Google Drive and create a folder for storing your notebooks, another folder for your data, and a folder for saving your models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSAEqKXnLNp6"
      },
      "source": [
        "## Task 2 Introduction to Keras\n",
        "\n",
        "Keras is the default high-level API for TensorFlow 2.x. For most jobs, Keras is often adequate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXEeTsA8N0qy"
      },
      "source": [
        "Let's first import TensorFlow and Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b5HHXVQNPMs"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "# print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKYiyKmlPN-D"
      },
      "source": [
        "### Task 2.1 Prepare training and testing data for TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVDftiAqM9Qe"
      },
      "source": [
        "Keras comes with a set of common datasets. There are already processed to be used for training Keras models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jpJv0QiNIPt"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "PZHbAojILCJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "metadata": {
        "id": "QLFa5nBZA1bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "id": "BUOKSBVhY54c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "metadata": {
        "id": "VV1FhIZ7A2_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0QxNaX9N_IL"
      },
      "source": [
        "**exercise**: Find out how many datasets are included in `keras.datasets`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from tensorflow.keras import datasets\n",
        "\n",
        "# List all attributes in the datasets module\n",
        "dataset_list = dir(datasets)  #list all attributes, methods, and datasets\n",
        "\n",
        "# Filter out all the private attributes (those that start with \"__\")\n",
        "public_dataset_list = [dataset for dataset in dataset_list if not dataset.startswith(\"__\")]\n",
        "\n",
        "# Now, public_dataset_list contains all the public datasets available\n",
        "number_of_datasets = len(public_dataset_list)\n",
        "\n",
        "print(\"Number of datasets in keras.datasets:\", number_of_datasets)\n",
        "print(\"Datasets names:\", public_dataset_list)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0snZ50804RlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV-3wYQMPC2D"
      },
      "source": [
        "You can see that this dataset is a collection of NumPy arrays. This is very similar for how you prepare data for training a machine learning model in scikit-learn.\n",
        "\n",
        "**exercise**: Find out the shape of the features (images) and labels. How many unique labels are in the training data and the testing data?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "print(len(np.unique(train_labels)))\n",
        "print(len(np.unique(test_labels)))"
      ],
      "metadata": {
        "id": "kAA1-k005oJd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seGJ_YMhsOZy"
      },
      "source": [
        "Let's have a look at the first image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J30m0nhAsE0m"
      },
      "source": [
        "import IPython.display\n",
        "import PIL.Image\n",
        "IPython.display.display(PIL.Image.fromarray(train_images[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_mNpKlfKxs2"
      },
      "source": [
        "Here, we reshape the images into 1-D NumPy arrays as we will be only using Dense layers. This is not always necessary or desirable if we use other layer types that expect 2-D or 3-D **tensors** as inputs.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0MhmHTIMGp4"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "test_images = test_images.reshape((10000, 28 * 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muti1NwmMT9a"
      },
      "source": [
        "Next we normalise the input data. Such  a normalisation step can also be done inside the model through a batch-normalisation layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjtc94yEMXTo"
      },
      "source": [
        "train_images = train_images.astype('float32') / 255  #[0,255]->[0,1]\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zBbsrlJR7Jc"
      },
      "source": [
        "Note how we convert the input to `float32`. For the output, we also encode it using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTBlAhBhR6gj"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)   ## convert the label into categorical using onehot\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "085TepE3A7st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k38UjevTkZ-"
      },
      "source": [
        "**qestion**: What is the shape of the output now?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "metadata": {
        "id": "hT6isk7Mfz9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9RAPZNoP-ne"
      },
      "source": [
        "### Task 2.2 Define a Keras model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f-7zvQWRJnp"
      },
      "source": [
        "There are three APIs to create a Keras model:\n",
        "\n",
        "- Sequential API\n",
        "- Functional API\n",
        "- Model subclassing\n",
        "\n",
        "The Sequential API is the simplest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya-0vbJkRrBT"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "network = models.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(28 * 28, )),\n",
        "    layers.Dense(10, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KymoVYyR1Ra"
      },
      "source": [
        "As shown above, the first layer need to have the `input_shape` defined. The comma at the end is necessary when the input is a 1-D tensor. (Try remove the comma and rerun the code above.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72PQwXpACWeR"
      },
      "source": [
        "Now you can visualise the sequential model in terms of its layers.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jorBWCPO_ATH"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(network, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0-g8ZbcCmdy"
      },
      "source": [
        "Note that the input and output tensors of each layer have dynamic shapes. That is why the first dimension (the batch dimension) is marked as `?`.\n",
        "\n",
        "**question**：What determines the output shape of each layer? The output shape of the last layer is 10. Can it be another value?\n",
        "\n",
        "**exercise**: Change the input shape of the above network to 32x32 and then visualise the network layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ2cJ283HgfB"
      },
      "source": [
        "### Task 2.3 Compile the model\n",
        "\n",
        "Now we are ready to set up the model for training. We need to specify the following three things:\n",
        "\n",
        "1. A loss function, which compares the model outputs against the training labels to provide training feedback.\n",
        "2. An optimiser, which uses the gradients of the loss function over model parameters to adjust parameter values.\n",
        "3. Metrics that we like to monitor during the training process.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbw3I29PJAZ2"
      },
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l-6FONEI-xq"
      },
      "source": [
        "Metrics are often different from the loss function. In the example above, the metric is accuracy while the loss is the cross-entropy.\n",
        "\n",
        "**question**: Why do we need metrics different from the loss function? Can we always use a metric to replace the loss function?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUpi72zeJ-Im"
      },
      "source": [
        "### Task 2.4 Training the model\n",
        "\n",
        "Once the network is defined and compiled, the training can start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d96En5qiRt5x"
      },
      "source": [
        "# save the initial weights for later experiments\n",
        "init_weights = network.get_weights()\n",
        "\n",
        "history = network.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s_ilExluFzQ"
      },
      "source": [
        "The loss function and training metrics can be recorded and visualised as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1uUcRIgxYDL"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot training loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXl83O7WxZOx"
      },
      "source": [
        "**question** Do you see overfitting from the plot above?\n",
        "\n",
        "**exercise** In the above example, try a different batch size. How does the training speed change?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aMMcGRwxQH9"
      },
      "source": [
        "### Task 2.5 Check model performance via test set\n",
        "\n",
        "In the end, you have to rely on the test dataset to assess the true model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbjLyK8ryCTY"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print(f'test_loss: {test_loss}')\n",
        "print(f'test_acc: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVkybT8VylET"
      },
      "source": [
        "The difference between train_loss and test_loss is called the **generalisation gap**. It is a measure of overfitting. We will later see how overfitting can be addressed by regularisation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1XQAobcnsUU"
      },
      "source": [
        "## Task 3 Use TensorBoard callbacks to monitor training\n",
        "\n",
        "Last week, we saw how `tf.summary` API can be used to log metrics. With Keras, TensorBoard logging can be much easier through callbacks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_tYc1bG0HQE"
      },
      "source": [
        "!rm -rf ./logs/\n",
        "\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "root_logdir = \"logs\"\n",
        "run_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = os.path.join(root_logdir, run_id)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=logdir,\n",
        "        histogram_freq=1\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "# reset the training\n",
        "network.set_weights(init_weights)\n",
        "\n",
        "history = network.fit(train_images,\n",
        "                      train_labels,\n",
        "                      epochs=20,\n",
        "                      batch_size=128,\n",
        "                      callbacks=callbacks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-slvZu13H5t"
      },
      "source": [
        "Now you can visualise the loss, the training metrics, the model graph, and even the histograms for each layers' activations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwWdGF8b0kBY",
        "cellView": "form"
      },
      "source": [
        "# @title\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEABV2Br7GnQ"
      },
      "source": [
        "**question** Inspect the graphs in TensorBoard. How is it different from the graph generated from the `plot_model` function above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbd7zbd1NW42"
      },
      "source": [
        "## Additional resources\n",
        "\n",
        "- Official [Keras overview](https://keras.io/about/)"
      ]
    }
  ]
}